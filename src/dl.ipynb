{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8257b60",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "20d945cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from dataloader import Trial\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c9fcd3a",
   "metadata": {},
   "source": [
    "## Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9b53d88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SAMPLE = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0e89a08f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\wing_\\Code\\ComputerVision\\HMC-Computer-Vision-Project\\data\\TH8\\TH8ST17A3D1000TS0_2.mov\n"
     ]
    }
   ],
   "source": [
    "if RANDOM_SAMPLE:\n",
    "    ROOT = os.path.dirname(os.getcwd())\n",
    "    DATA_DIR = os.path.join(ROOT, 'data')\n",
    "    FIN_DIR = os.path.join(DATA_DIR, random.choice(list(filter(lambda x: os.path.isdir(os.path.join(DATA_DIR, x)), os.listdir(DATA_DIR)))))\n",
    "\n",
    "    # FIN_DIR = os.path.join(DATA_DIR, Random.choice(FIN_THICKNESSES))\n",
    "    VIDEO_PATH = os.path.join(FIN_DIR, random.choice(list(filter(lambda x: os.path.splitext(x)[1]=='.mov', os.listdir(FIN_DIR)))))\n",
    "else:\n",
    "    VIDEO_PATH = r'..\\data\\TH8\\TH8ST17A3D250TS0_2.mov' \n",
    "\n",
    "print(VIDEO_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e5e32db",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "386ceffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_img(img, img_name):\n",
    "    cv2.imwrite(os.path.join(os.path.dirname(os.getcwd()), 'saved_imgs', img_name)+'.png', img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea8d959",
   "metadata": {},
   "source": [
    "## Dynamic Feature Detection\n",
    "Pre-processing includes four steps\n",
    "1. We need to load our *.mov* file in as our Trial object. \n",
    "2. We convert to grayscale to reduce the information to process (and remove color variation)\n",
    "3. Then, in preparation to \"remove\" the background from the video, we need to reduce the contrast\n",
    "4. Lastly we need to remove the background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "28ac9c0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800\n"
     ]
    }
   ],
   "source": [
    "recording = Trial(VIDEO_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3b870a94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<dataloader.Trial at 0x21747266190>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recording.to_gray(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ca4f754",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<dataloader.Trial at 0x21755596270>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# recording.change_contrast(alpha=0.5, beta=2, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cb550f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "recording.remove_avg(skipframes=100, the_fake_one=False)  # Skip the beginning to avoid heavy imprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3da545",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<dataloader.Trial at 0x21747266190>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recording.change_contrast(alpha=15, beta=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7b328edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "recording.remove_avg(the_fake_one=False)  # Skip the beginning to avoid heavy imprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "078c0fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "recording.play_video()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6cf1ee3",
   "metadata": {},
   "source": [
    "Here, we will create a copy (because we were too lazy to create an undo feature) to act as a checkpoint. We can optionally use a morphological transformation to try to fill out the air pockets as much as possible. We also check our work here at the end of this. We now have our mask for our dynamic components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9426f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "out:Trial = recording.ranger(minval=120, maxval=240)\n",
    "out.closing(inplace=True, ksize=(15, 15))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b6add1",
   "metadata": {},
   "source": [
    "### Error Checking\n",
    "\n",
    "We can now check our mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a820a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "out.play_video()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ffbcd0",
   "metadata": {},
   "source": [
    "To ensure the accuracy of our mask, we will use one of the best, most robust vision systems: the human eye. We will overlay our mask to highlight the masked areas to a brighter level than the non-masked area. This is not super effective for spotting holes in bubble masks, but it is great for spotting missed bubbles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec11cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "rec1 = Trial(VIDEO_PATH)\n",
    "rec1.apply_mask(out, inplace=True)\n",
    "rec1.play_video()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ad8512",
   "metadata": {},
   "source": [
    "## Waterline Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79b0bcb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
