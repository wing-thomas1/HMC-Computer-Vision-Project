{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8257b60",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d945cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from dataloader import MOVE\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c9fcd3a",
   "metadata": {},
   "source": [
    "## Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b53d88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SAMPLE = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e5e32db",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e89a08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_path(rando : bool) -> str:\n",
    "    if rando==True:\n",
    "        ROOT = os.path.dirname(os.getcwd())\n",
    "        DATA_DIR = os.path.join(ROOT, 'data')\n",
    "        FIN_DIR = os.path.join(DATA_DIR, random.choice(list(filter(lambda x: os.path.isdir(os.path.join(DATA_DIR, x)), os.listdir(DATA_DIR)))))\n",
    "        vp = os.path.join(FIN_DIR, random.choice(list(filter(lambda x: os.path.splitext(x)[1]=='.mov', os.listdir(FIN_DIR)))))\n",
    "    else:\n",
    "        vp = r'..\\data\\TH16\\TH16ST25A2D1000TS0_2.mov'\n",
    "\n",
    "    print(vp)\n",
    "\n",
    "    return vp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea8d959",
   "metadata": {},
   "source": [
    "## Dynamic Feature Detection\n",
    "Pre-processing includes four steps\n",
    "1. We need to load our *.mov* file in as our MOVE object. \n",
    "2. We convert to grayscale to reduce the information to process (and remove color variation)\n",
    "3. Then, in preparation to \"remove\" the background from the video, we need to reduce the contrast\n",
    "4. Lastly we need to remove the background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ac9c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vid_path = generate_path(False)\n",
    "recording = MOVE(vid_path)\n",
    "recording.play_video( )\n",
    "recording.to_gray(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8fc40e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "recording.change_contrast(alpha=0.5, beta=2, inplace=True)\n",
    "recording.remove_avg(skipframes=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078c0fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "recording.play_video()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6cf1ee3",
   "metadata": {},
   "source": [
    "Here, we will create a copy (because we were too lazy to create an undo feature) to act as a checkpoint. We can optionally use a morphological transformation to try to fill out the air pockets as much as possible. We also check our work here at the end of this. We now have our mask for our dynamic components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9426f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "out:MOVE = recording.ranger(minval=100, maxval=240)\n",
    "out.closing(inplace=True, ksize=(5,5), iterations=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b6add1",
   "metadata": {},
   "source": [
    "### Error Checking\n",
    "\n",
    "We can now check our mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a820a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "out.play_video()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ffbcd0",
   "metadata": {},
   "source": [
    "To ensure the accuracy of our mask, we will use one of the best, most robust vision systems: the human eye. We will overlay our mask to highlight the masked areas to a brighter level than the non-masked area. This is not super effective for spotting holes in bubble masks, but it is great for spotting missed bubbles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec11cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "rec1 = MOVE(vid_path)\n",
    "rec1.apply_mask(out, inplace=True)\n",
    "rec1.play_video()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ad8512",
   "metadata": {},
   "source": [
    "## Waterline Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79b0bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "recording = MOVE(vid_path)\n",
    "recording.to_gray(inplace=True)\n",
    "# vid_path = generate_path(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243e4a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "recording.play_video()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da079eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "background = recording.get_avg()\n",
    "background = cv2.GaussianBlur(background, (1111, 1), sigmaX=32000, borderType=cv2.BORDER_REFLECT)\n",
    "MOVE.show(background)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9077a354",
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = np.float32(background.reshape((-1, 3)))\n",
    "\n",
    "criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10, 1.0)\n",
    "criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10, 1.0)\n",
    "_, labels, centers = cv2.kmeans(Z, 3, None, criteria, 10, cv2.KMEANS_RANDOM_CENTERS)\n",
    "\n",
    "centers = np.uint8(centers)\n",
    "quantized = centers[labels.flatten()]\n",
    "quantized = quantized.reshape(background.shape)\n",
    "MOVE.show(quantized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6acb8320",
   "metadata": {},
   "outputs": [],
   "source": [
    "yMin = quantized.shape[1]//4\n",
    "darkestColor = np.unique(quantized).min()\n",
    "\n",
    "half_mask:np.ndarray = np.ones_like(quantized)\n",
    "half_mask[:yMin, :] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3e2bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "waterline = 255*np.where(quantized[:, ] == darkestColor, half_mask, np.zeros_like(recording.frames[0]))\n",
    "MOVE.show(waterline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0041f334",
   "metadata": {},
   "outputs": [],
   "source": [
    "rec2 = MOVE(vid_path)\n",
    "temp = MOVE(vid_path)\n",
    "temp.img_like(img=waterline, inplace=True)\n",
    "rec2.apply_mask(temp, inplace=True)\n",
    "rec2.play_video()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73b1010",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp.combine_masks(out, inplace=True)\n",
    "temp.play_video()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f788cbdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(temp.frames)):\n",
    "    final_frame = temp.frames[i]\n",
    "    max_bright = final_frame.max()\n",
    "    final_frame = final_frame.T\n",
    "    for r, row in enumerate(final_frame):\n",
    "        min_ind = np.where(row == max_bright)[0][0]\n",
    "        final_frame[r][:min_ind] = 0\n",
    "\n",
    "    temp.frames[i] = final_frame.T\n",
    "\n",
    "temp.play_video()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
